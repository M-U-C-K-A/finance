#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
FinAnalytics PDF System - Syst√®me simplifi√© et robuste
Un seul script pour tout g√©rer : scraping, traitement et interface
"""

import os
import sys
import time
import json
import logging
import argparse
import threading
from datetime import datetime
from pathlib import Path

# Configuration automatique de l'environnement
def setup_environment():
    """Configure automatiquement l'environnement"""
    
    # Cr√©er les dossiers n√©cessaires
    dirs = ['data', 'temp_charts', 'generated_reports', '../public/reports']
    for d in dirs:
        Path(d).mkdir(parents=True, exist_ok=True)
    
    # R√©cup√©rer l'URL de la base de donn√©es
    db_url = None
    for env_file in ['.env', '../.env']:
        if os.path.exists(env_file):
            with open(env_file, 'r') as f:
                for line in f:
                    if line.startswith('DATABASE_URL='):
                        db_url = line.split('=', 1)[1].strip().strip('"')
                        break
    
    if not db_url:
        db_url = 'postgresql://admin:@localhost:5433/finance'
    
    # Cr√©er le fichier .env local
    with open('.env', 'w') as f:
        f.write(f'DATABASE_URL="{db_url}"\n')
    
    return db_url

# Logging configuration
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('finanalytics.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class FinAnalyticsSystem:
    
    def __init__(self):
        self.db_url = setup_environment()
        self.running = False
        logger.info("üöÄ FinAnalytics PDF System initialis√©")
        logger.info(f"üìä Base de donn√©es: {self.db_url}")
    
    def test_system(self):
        """Test rapide du syst√®me"""
        logger.info("üß™ Tests syst√®me...")
        
        try:
            # Test base de donn√©es
            import psycopg2
            conn = psycopg2.connect(self.db_url)
            cursor = conn.cursor()
            cursor.execute('SELECT COUNT(*) FROM "reports"')
            count = cursor.fetchone()[0]
            conn.close()
            logger.info(f"‚úÖ Base de donn√©es OK - {count} rapports")
        except Exception as e:
            logger.error(f"‚ùå Base de donn√©es: {e}")
            return False
        
        try:
            # Test scraping
            import yfinance as yf
            ticker = yf.Ticker("AAPL")
            info = ticker.info
            if info:
                logger.info("‚úÖ Scraping OK")
            else:
                raise Exception("Pas de donn√©es")
        except Exception as e:
            logger.error(f"‚ùå Scraping: {e}")
            return False
        
        try:
            # Test PDF
            from reportlab.lib.pagesizes import A4
            from reportlab.platypus import SimpleDocTemplate
            test_file = "test.pdf"
            doc = SimpleDocTemplate(test_file, pagesize=A4)
            doc.build([])
            os.remove(test_file)
            logger.info("‚úÖ PDF OK")
        except Exception as e:
            logger.error(f"‚ùå PDF: {e}")
            return False
        
        logger.info("üéâ Tous les tests OK!")
        return True
    
    def scrape_data(self):
        """Scrape les donn√©es de march√©"""
        logger.info("üìä D√©but du scraping...")
        
        try:
            import yfinance as yf
            import pandas as pd
            
            # Tickers principaux
            tickers = ['AAPL', 'MSFT', 'GOOGL', '^GSPC', '^DJI', 'BTC-USD', 'ETH-USD']
            
            today = datetime.now().strftime("%Y-%m-%d")
            data_dir = Path('data') / today
            data_dir.mkdir(exist_ok=True)
            
            success = 0
            for ticker in tickers:
                try:
                    stock = yf.Ticker(ticker)
                    hist = stock.history(period="5d")
                    info = stock.info
                    
                    if not hist.empty:
                        hist.to_csv(data_dir / f"{ticker}_history.csv")
                        
                    if info:
                        with open(data_dir / f"{ticker}_info.json", 'w') as f:
                            json.dump(info, f, indent=2, default=str)
                    
                    success += 1
                    logger.info(f"‚úÖ {ticker} OK")
                    time.sleep(1)  # Rate limiting
                    
                except Exception as e:
                    logger.error(f"‚ùå {ticker}: {e}")
            
            logger.info(f"üìä Scraping termin√©: {success}/{len(tickers)} OK")
            return success > 0
            
        except Exception as e:
            logger.error(f"‚ùå Erreur scraping: {e}")
            return False
    
    def process_reports(self):
        """Traite les rapports en attente"""
        logger.info("üîÑ D√©but du traitement des rapports...")
        
        try:
            import psycopg2
            import psycopg2.extras
            
            conn = psycopg2.connect(self.db_url)
            cursor = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
            
            # R√©cup√©rer les rapports PENDING
            cursor.execute("""
                SELECT id, "userId", "assetSymbol", title, "reportType"
                FROM "reports" 
                WHERE status = 'PENDING'
                ORDER BY "createdAt" ASC
                LIMIT 10
            """)
            
            reports = cursor.fetchall()
            
            if not reports:
                logger.info("üìã Aucun rapport en attente")
                conn.close()
                return True
            
            for report in reports:
                try:
                    logger.info(f"üîÑ Traitement rapport {report['id']} ({report['assetSymbol']})")
                    
                    # Marquer comme en cours
                    cursor.execute("""
                        UPDATE "reports" 
                        SET status = 'PROCESSING', "processingStartedAt" = NOW(), "updatedAt" = NOW()
                        WHERE id = %s
                    """, (report['id'],))
                    conn.commit()
                    
                    # G√©n√©rer le PDF r√©el
                    pdf_path = self.generate_real_pdf(report)
                    
                    if not pdf_path:
                        raise Exception("√âchec de g√©n√©ration PDF")
                    
                    cursor.execute("""
                        UPDATE "reports" 
                        SET status = 'COMPLETED', "completedAt" = NOW(), "pdfPath" = %s, "updatedAt" = NOW()
                        WHERE id = %s
                    """, (pdf_path, report['id']))
                    conn.commit()
                    
                    logger.info(f"‚úÖ Rapport {report['id']} termin√©")
                    
                except Exception as e:
                    logger.error(f"‚ùå Erreur rapport {report['id']}: {e}")
                    cursor.execute("""
                        UPDATE "reports" 
                        SET status = 'FAILED', "failureReason" = %s, "updatedAt" = NOW()
                        WHERE id = %s
                    """, (str(e), report['id']))
                    conn.commit()
            
            conn.close()
            logger.info(f"üîÑ Traitement termin√©: {len(reports)} rapports trait√©s")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement: {e}")
            return False
    
    def run_daemon(self):
        """Lance le daemon de traitement"""
        logger.info("üöÄ D√©marrage du daemon FinAnalytics")
        self.running = True
        
        last_scrape = 0
        scrape_interval = 6 * 3600  # 6 heures
        
        while self.running:
            try:
                # Traitement des rapports (toutes les 30 secondes)
                self.process_reports()
                
                # Scraping (toutes les 6 heures)
                now = time.time()
                if now - last_scrape > scrape_interval:
                    self.scrape_data()
                    last_scrape = now
                
                time.sleep(30)
                
            except KeyboardInterrupt:
                logger.info("üõë Arr√™t demand√© par l'utilisateur")
                self.running = False
            except Exception as e:
                logger.error(f"‚ùå Erreur daemon: {e}")
                time.sleep(60)  # Attendre avant de retry
    
    def generate_real_pdf(self, report):
        """G√©n√®re un PDF selon le type de rapport demand√©"""
        try:
            # D√©terminer le type de rapport
            report_type = report.get('reportType', 'SIMPLE')
            symbol = report['assetSymbol']
            
            logger.info(f"üìÑ G√©n√©ration PDF type {report_type} pour {symbol}")
            
            # G√©n√©rer le timestamp et nom de fichier
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Nom de fichier selon le type
            type_prefix = {
                'SIMPLE': 'SIMPLE_RAPPORT',
                'COMPLETE': 'ULTRA_RAPPORT', 
                'BENCHMARK': 'BENCHMARK_RAPPORT',
                'PRICER': 'PRICER_RAPPORT'
            }
            
            pdf_filename = f"{type_prefix.get(report_type, 'RAPPORT')}_{symbol}_{timestamp}.pdf"
            
            # Cr√©er dans le dossier public pour que l'API puisse le servir
            public_reports_dir = Path("../public/reports")
            public_reports_dir.mkdir(parents=True, exist_ok=True)
            
            pdf_path = public_reports_dir / pdf_filename
            
            # S√©lectionner le g√©n√©rateur appropri√©
            if report_type == 'SIMPLE':
                success = self.generate_simple_pdf(report, str(pdf_path))
            elif report_type == 'COMPLETE':
                from ultra_premium_pdf_generator import UltraPremiumPDFGenerator
                generator = UltraPremiumPDFGenerator(symbol, str(pdf_path))
                success = generator.run_complete_analysis()
            elif report_type == 'BENCHMARK':
                success = self.generate_benchmark_pdf(report, str(pdf_path))
            elif report_type == 'PRICER':
                success = self.generate_pricer_pdf(report, str(pdf_path))
            else:
                # Fallback au g√©n√©rateur complet
                from ultra_premium_pdf_generator import UltraPremiumPDFGenerator
                generator = UltraPremiumPDFGenerator(symbol, str(pdf_path))
                success = generator.run_complete_analysis()
            
            if not success:
                raise Exception(f"√âchec de l'analyse {report_type}")
            
            # V√©rifier que le fichier a √©t√© cr√©√©
            if not pdf_path.exists():
                raise Exception("Le fichier PDF n'a pas √©t√© cr√©√©")
            
            logger.info(f"‚úÖ PDF {report_type} g√©n√©r√©: {pdf_filename}")
            logger.info(f"üìä Taille du fichier: {pdf_path.stat().st_size / 1024 / 1024:.2f} MB")
            
            # Retourner le nom du fichier (pas le chemin complet)
            return pdf_filename
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration PDF ultra-complet: {e}")
            
            # Fallback vers l'ancien syst√®me si n√©cessaire
            try:
                logger.info("üîÑ Fallback vers l'ancien g√©n√©rateur...")
                return self.generate_fallback_pdf(report)
            except:
                return None

    def generate_fallback_pdf(self, report):
        """G√©n√©rateur PDF de secours (ancien syst√®me)"""
        try:
            import yfinance as yf
            from simple_charts import create_charts
            from simple_pdf import generate_pdf_report
            
            symbol = report['assetSymbol']
            logger.info(f"üìÑ G√©n√©ration PDF fallback pour {symbol}")
            
            # R√©cup√©rer les donn√©es
            stock = yf.Ticker(symbol)
            hist = stock.history(period="5y")
            info = stock.info
            
            if hist.empty:
                raise Exception(f"Pas de donn√©es pour {symbol}")
            
            # Donn√©es pour le rapport
            data = {
                'ticker': symbol,
                'info': info,
                'history': hist,
                'financials': None,
                'balance_sheet': None,
                'cashflow': None
            }
            
            # Essayer de r√©cup√©rer les donn√©es financi√®res (optionnel)
            try:
                data['financials'] = stock.financials
                data['balance_sheet'] = stock.balance_sheet
                data['cashflow'] = stock.cashflow
            except:
                pass  # Pas grave si √ßa √©choue
            
            # Cr√©er les graphiques
            charts_path = create_charts(data)
            
            # G√©n√©rer le PDF
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            pdf_filename = f"rapport_fallback_{symbol}_{timestamp}.pdf"
            
            # Cr√©er dans le dossier public pour que l'API puisse le servir
            public_reports_dir = Path("../public/reports")
            public_reports_dir.mkdir(parents=True, exist_ok=True)
            
            pdf_path = public_reports_dir / pdf_filename
            
            # G√©n√©rer le PDF
            report_data = {
                'symbol': symbol,
                'company_name': info.get('longName', symbol),
                'report_date': datetime.now().strftime("%d/%m/%Y"),
                'current_price': float(hist['Close'].iloc[-1]),
                'charts_path': charts_path,
                'period_return': ((hist['Close'].iloc[-1] / hist['Close'].iloc[0]) - 1) * 100
            }
            
            generate_pdf_report(report_data, str(pdf_path))
            
            logger.info(f"‚úÖ PDF fallback g√©n√©r√©: {pdf_filename}")
            
            # Retourner le nom du fichier (pas le chemin complet)
            return pdf_filename
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration PDF fallback: {e}")
            return None
    
    def generate_simple_pdf(self, report, pdf_path):
        """G√©n√®re un rapport simple (8-10 pages)"""
        try:
            from premium_pdf_generator import PremiumPDFGenerator
            
            symbol = report['assetSymbol']
            logger.info(f"üìÑ G√©n√©ration PDF SIMPLE pour {symbol}")
            
            # Utiliser le g√©n√©rateur premium mais en mode simple
            generator = PremiumPDFGenerator(symbol, pdf_path)
            return generator.run_simple_analysis()
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration PDF simple: {e}")
            return False
    
    def generate_benchmark_pdf(self, report, pdf_path):
        """G√©n√®re un rapport avec comparaisons benchmark"""
        try:
            from ultra_premium_pdf_generator import UltraPremiumPDFGenerator
            
            symbol = report['assetSymbol']
            selected_benchmarks = report.get('selectedBenchmarks', [])
            
            logger.info(f"üìÑ G√©n√©ration PDF BENCHMARK pour {symbol} vs {selected_benchmarks}")
            
            # Cr√©er le g√©n√©rateur avec benchmarks
            generator = UltraPremiumPDFGenerator(symbol, pdf_path)
            return generator.run_benchmark_analysis(selected_benchmarks)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration PDF benchmark: {e}")
            return False
    
    def generate_pricer_pdf(self, report, pdf_path):
        """G√©n√®re un rapport avec mod√®les de pricing avanc√©s"""
        try:
            from ultra_premium_pdf_generator import UltraPremiumPDFGenerator
            
            symbol = report['assetSymbol']
            pricing_params = report.get('customPricingParams', {})
            
            logger.info(f"üìÑ G√©n√©ration PDF PRICER pour {symbol}")
            
            # Cr√©er le g√©n√©rateur avec param√®tres de pricing
            generator = UltraPremiumPDFGenerator(symbol, pdf_path)
            return generator.run_pricer_analysis(pricing_params)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration PDF pricer: {e}")
            return False
    
    def show_status(self):
        """Affiche le statut du syst√®me"""
        logger.info("üìã Statut du syst√®me FinAnalytics")
        
        try:
            import psycopg2
            conn = psycopg2.connect(self.db_url)
            cursor = conn.cursor()
            
            # Statistiques des rapports
            cursor.execute("""
                SELECT status, COUNT(*) 
                FROM "reports" 
                GROUP BY status
            """)
            stats = cursor.fetchall()
            
            logger.info("üìä Statistiques des rapports:")
            for status, count in stats:
                logger.info(f"  {status}: {count}")
            
            # Derniers rapports
            cursor.execute("""
                SELECT id, "assetSymbol", status, "createdAt"
                FROM "reports" 
                ORDER BY "createdAt" DESC 
                LIMIT 5
            """)
            recent = cursor.fetchall()
            
            logger.info("üìã Derniers rapports:")
            for row in recent:
                logger.info(f"  {row[1]} ({row[2]}) - {row[3]}")
            
            conn.close()
            
        except Exception as e:
            logger.error(f"‚ùå Erreur statut: {e}")

def main():
    parser = argparse.ArgumentParser(description='FinAnalytics PDF System')
    parser.add_argument('action', choices=['test', 'scrape', 'process', 'daemon', 'status'], 
                       help='Action √† ex√©cuter')
    
    args = parser.parse_args()
    
    system = FinAnalyticsSystem()
    
    if args.action == 'test':
        success = system.test_system()
        sys.exit(0 if success else 1)
    
    elif args.action == 'scrape':
        success = system.scrape_data()
        sys.exit(0 if success else 1)
    
    elif args.action == 'process':
        success = system.process_reports()
        sys.exit(0 if success else 1)
    
    elif args.action == 'daemon':
        system.run_daemon()
    
    elif args.action == 'status':
        system.show_status()

if __name__ == "__main__":
    main()